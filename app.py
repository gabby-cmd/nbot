import streamlit as st
from query_engine import Chatbot
from document_processor import DocumentProcessor

# ‚úÖ Load Neo4j Credentials from Streamlit Secrets
import os

NEO4J_URI = os.getenv("NEO4J_URI", st.secrets["NEO4J_URI"])
NEO4J_USER = os.getenv("NEO4J_USER", st.secrets["NEO4J_USER"])
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", st.secrets["NEO4J_PASSWORD"])

# ‚úÖ Initialize Neo4j Chatbot & Document Processor
chatbot = Chatbot(uri=NEO4J_URI, user=NEO4J_USER, password=NEO4J_PASSWORD)
processor = DocumentProcessor(uri=NEO4J_URI, user=NEO4J_USER, password=NEO4J_PASSWORD)

# ‚úÖ Streamlit UI Title
st.title("üìö Knowledge Graph Chatbot")

# ‚úÖ File Upload Section
st.header("Upload a Document to Add to Knowledge Graph")
uploaded_file = st.file_uploader("Choose a PDF file", type=["pdf"])

if uploaded_file:
    st.write("üìÇ Processing file...")
    
    # ‚úÖ Save file temporarily
    temp_file_path = f"/tmp/{uploaded_file.name}"
    with open(temp_file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # ‚úÖ Process PDF & store in Neo4j
    try:
        processor.process_pdf(temp_file_path)
        st.success("‚úÖ File processed successfully! Knowledge Graph updated.")
    except Exception as e:
        st.error(f"‚ö†Ô∏è Error processing document: {e}")

# ‚úÖ Chatbot Query Input
st.header("üí¨ Ask the Chatbot")
user_input = st.text_input("Ask a question about the knowledge graph:")

if st.button("Send"):
    if user_input:
        with st.chat_message("user"):
            st.write(user_input)

        with st.chat_message("assistant"):
            response_stream = chatbot.chat(user_input)  # **Call chatbot**
            response_placeholder = st.empty()  # **Placeholder for streaming text**
            full_response = ""

            for chunk in response_stream:
                if isinstance(chunk, str):  # ‚úÖ Ensure chunk is a string
                    full_response += chunk  
                elif hasattr(chunk, "text"):  # ‚úÖ If chunk is an object, extract its text
                    full_response += chunk.text  
                else:
                    print(f"‚ö†Ô∏è Unexpected chunk format: {chunk}")  # Debugging message
                
                response_placeholder.write(full_response)  # ‚úÖ Update UI dynamically
