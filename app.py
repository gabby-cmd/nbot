import streamlit as st
from query_engine import Chatbot
from document_processor import DocumentProcessor

# âœ… Load Neo4j credentials from Streamlit secrets
URI = st.secrets["neo4j"]["uri"]
USER = st.secrets["neo4j"]["user"]
PASSWORD = st.secrets["neo4j"]["password"]

# âœ… Initialize Neo4j document processor
processor = DocumentProcessor(uri=URI, user=USER, password=PASSWORD)

# âœ… Initialize chatbot
chatbot = Chatbot()

st.title("ğŸ“š Knowledge Graph Chatbot")

### **ğŸ”¹ Upload and Process Documents**
st.sidebar.header("ğŸ“‚ Upload a Document")
uploaded_file = st.sidebar.file_uploader("Upload a PDF document", type=["pdf"])

if uploaded_file:
    with st.spinner("Processing document... â³"):
        try:
            # âœ… Save uploaded file locally
            file_path = os.path.join("uploads", uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            # âœ… Process PDF and store chunks in Neo4j
            processor.process_pdf(file_path)

            st.sidebar.success("âœ… Document processed and stored in Neo4j!")

        except Exception as e:
            st.error(f"ğŸš¨ Error processing document: {e}")

### **ğŸ”¹ Chatbot Interface**
st.header("ğŸ¤– Chat with the Knowledge Graph")

user_input = st.text_input("Ask a question:")
if st.button("Send"):
    if user_input:
        with st.chat_message("user"):
            st.write(user_input)

        with st.chat_message("assistant"):
            response_stream = chatbot.chat(user_input)  # Call chatbot
            response_placeholder = st.empty()  # Placeholder for streamed text
            full_response = ""

            for chunk in response_stream:
                full_response += chunk.text  # Append streamed text
                response_placeholder.write(full_response)  # Update UI dynamically
